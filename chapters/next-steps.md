---
title: 'Next steps'
description:
  "Now that you have a working model, here are some things you can try with AllenNLP!"
prev: /training-and-prediction
next: null
type: chapter
id: 204
---

<textblock>

In the previous two chapters, we were able to quickly build a working NLP model using AllenNLP, although we just scratched the surface of what the library has to offer so far. AllenNLP offers more models, modules, and features that make it easier to develop a wide range of NLP applications. In this chapter, we'll give you a preview of some more things you can try with AllenNLP, along with some pointers to later chapters that give you more detail on individual topics.

</textblock>

<exercise id="1" title="Switching to pre-trained contextualizers">

* A few words on related abstractions (Seq2Vec encoder and TokenEmbedder)
* Using ELMo
* Using BERT

</exercise>

<exercise id="2" title="More AllenNLP commands">

* allennlp configure (config wizard)
* allennlp fine-tune

</exercise>

<exercise id="3" title="Running a demo">

* Running a simple server demo
* Customizing the demo

</exercise>

<exercise id="4" title="Using GPUs and Docker">

* Using GPUs
* Using Docker

</exercise>
